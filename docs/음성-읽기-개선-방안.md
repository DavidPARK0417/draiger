# ìŒì„± ì½ê¸° ê¸°ëŠ¥ ê°œì„  ë°©ì•ˆ (edge-TTS ì°¸ê³ )

> ì‘ì„±ì¼: 2026ë…„ 1ì›”  
> ì°¸ê³ : [edge-TTS GitHub](https://github.com/kss2002/edge-TTS)

## ğŸ“‹ ê°œìš”

í˜„ì¬ Web Speech APIë¥¼ ì‚¬ìš©í•˜ëŠ” ìŒì„± ì½ê¸° ê¸°ëŠ¥ì„ Microsoft Edge TTS ì—”ì§„ì„ í™œìš©í•œ edge-TTSë¡œ ê°œì„ í•˜ëŠ” ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.

---

## ğŸ¯ ê°œì„  ëª©í‘œ

1. **ê³ í’ˆì§ˆ ìŒì„±**: ë” ìì—°ìŠ¤ëŸ½ê³  ì¸ê°„ì ì¸ ëª©ì†Œë¦¬ ì œê³µ
2. **ë‹¤ì–‘í•œ ë³´ì´ìŠ¤**: ì„ í¬, ì¸ì¤€, í˜„ìˆ˜ ë“± ì—¬ëŸ¬ í•œêµ­ì–´ ë³´ì´ìŠ¤ ì„ íƒ ê°€ëŠ¥
3. **í–¥ìƒëœ í’ˆì§ˆ**: ë‹¨ì–´ ë‹¨ìœ„ ëŠê¹€ ë¬¸ì œ í•´ê²°
4. **ë¬´ì œí•œ ì‚¬ìš©**: ê¸€ì ìˆ˜ ì œí•œ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥

---

## ğŸ”§ êµ¬í˜„ ë°©ì•ˆ

### ë°©ì•ˆ 1: Next.js API Route + edge-tts ì„œë²„ (ê¶Œì¥)

**ì¥ì :**
- ì™„ì „í•œ ì œì–´ ê°€ëŠ¥
- ê³ í’ˆì§ˆ ìŒì„± ë³´ì¥
- ë‹¤ì–‘í•œ ë³´ì´ìŠ¤ ì„ íƒ ê°€ëŠ¥

**ë‹¨ì :**
- ë³„ë„ì˜ Python ì„œë²„ í•„ìš”
- ì„œë²„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©

**êµ¬í˜„ ë°©ë²•:**

#### 1-1. Python ì„œë²„ êµ¬ì¶• (ë³„ë„ ì„œë²„)

```python
# server/edge_tts_server.py
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
import edge_tts
import asyncio
import io

app = FastAPI()

@app.post("/api/tts")
async def text_to_speech(text: str, voice: str = "ko-KR-SunHiNeural", rate: str = "+0%"):
    try:
        communicate = edge_tts.Communicate(text, voice, rate=rate)
        audio_data = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_data += chunk["data"]
        
        return StreamingResponse(
            io.BytesIO(audio_data),
            media_type="audio/mpeg",
            headers={"Content-Disposition": "attachment; filename=speech.mp3"}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

#### 1-2. Next.js API Routeì—ì„œ í˜¸ì¶œ

```typescript
// src/app/api/tts/route.ts
export async function POST(request: Request) {
  const { text, voice = 'ko-KR-SunHiNeural', rate = '+0%' } = await request.json();
  
  try {
    const response = await fetch('http://localhost:8000/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text, voice, rate }),
    });
    
    return new Response(response.body, {
      headers: {
        'Content-Type': 'audio/mpeg',
      },
    });
  } catch (error) {
    return new Response('TTS ì˜¤ë¥˜ ë°œìƒ', { status: 500 });
  }
}
```

---

### ë°©ì•ˆ 2: ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ edge-tts API í˜¸ì¶œ (ê°„ë‹¨)

**ì¥ì :**
- ë³„ë„ ì„œë²„ ë¶ˆí•„ìš”
- êµ¬í˜„ ê°„ë‹¨

**ë‹¨ì :**
- Microsoft Edge API ì˜ì¡´
- CORS ì´ìŠˆ ê°€ëŠ¥ì„±

**êµ¬í˜„ ë°©ë²•:**

```typescript
// src/components/TextToSpeechEdge.tsx
'use client';

import { useState } from 'react';

export default function TextToSpeechEdge({ text }: { text: string }) {
  const [isPlaying, setIsPlaying] = useState(false);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  const handlePlay = async () => {
    try {
      // edge-tts API ì§ì ‘ í˜¸ì¶œ (CORS ì´ìŠˆ ê°€ëŠ¥)
      const response = await fetch(
        `https://speech.platform.bing.com/consumer/speech/synthesize/readaloud/voices/list?trustedclienttoken=6A5AA1D4EAFF4E9FB37E23D68491D6F4`,
        {
          method: 'GET',
          headers: {
            'User-Agent': 'Mozilla/5.0',
          },
        }
      );
      
      // ì‹¤ì œ êµ¬í˜„ì€ ë” ë³µì¡í•¨
      // ëŒ€ì‹  ë°©ì•ˆ 1 ê¶Œì¥
    } catch (error) {
      console.error('TTS ì˜¤ë¥˜:', error);
    }
  };

  return (
    <button onClick={handlePlay}>
      {isPlaying ? 'ì •ì§€' : 'ì¬ìƒ'}
    </button>
  );
}
```

---

### ë°©ì•ˆ 3: Web Speech API ê°œì„  (í˜„ì¬ ë°©ì‹ ìœ ì§€ + ê°œì„ )

**ì¥ì :**
- ë³„ë„ ì„œë²„ ë¶ˆí•„ìš”
- ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥
- ë¸Œë¼ìš°ì € ë„¤ì´í‹°ë¸Œ ì§€ì›

**ë‹¨ì :**
- í’ˆì§ˆ ì œí•œ
- ë³´ì´ìŠ¤ ì„ íƒ ì œí•œ

**ê°œì„  ì‚¬í•­:**

1. **ë” ë‚˜ì€ ë³´ì´ìŠ¤ ì„ íƒ**
```typescript
// í•œêµ­ì–´ ë³´ì´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
const voices = window.speechSynthesis.getVoices();
const koreanVoices = voices.filter(voice => 
  voice.lang.startsWith('ko') || voice.lang.includes('Korean')
);

// ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ë³´ì´ìŠ¤ ì„ íƒ
const bestVoice = koreanVoices.find(voice => 
  voice.name.includes('Neural') || voice.name.includes('Premium')
) || koreanVoices[0];
```

2. **SSML ì‚¬ìš© (ì§€ì›ë˜ëŠ” ê²½ìš°)**
```typescript
// SSMLë¡œ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸°
const ssmlText = `
  <speak>
    <prosody rate="${speechRate}">
      ${text}
    </prosody>
  </speak>
`;
```

---

## ğŸ¨ ê¶Œì¥ êµ¬í˜„: í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹

**í˜„ì¬ Web Speech API ìœ ì§€ + edge-TTS ì˜µì…˜ ì œê³µ**

### êµ¬í˜„ ê³„íš

1. **ê¸°ë³¸**: Web Speech API ì‚¬ìš© (í˜„ì¬ ë°©ì‹)
2. **ê³ ê¸‰**: edge-TTS ì„œë²„ ì—°ë™ ì˜µì…˜ ì œê³µ
3. **ì‚¬ìš©ì ì„ íƒ**: ì„¤ì •ì—ì„œ TTS ì—”ì§„ ì„ íƒ ê°€ëŠ¥

```typescript
// src/components/TextToSpeech.tsx
interface TextToSpeechProps {
  content: string;
  title: string;
  metaDescription?: string;
  engine?: 'web-speech' | 'edge-tts'; // ì—”ì§„ ì„ íƒ
  voice?: string; // edge-tts ë³´ì´ìŠ¤ ì„ íƒ
}

export default function TextToSpeech({ 
  content, 
  title, 
  metaDescription,
  engine = 'web-speech',
  voice = 'ko-KR-SunHiNeural'
}: TextToSpeechProps) {
  // engineì— ë”°ë¼ ë‹¤ë¥¸ êµ¬í˜„ ì‚¬ìš©
  if (engine === 'edge-tts') {
    return <TextToSpeechEdge content={content} voice={voice} />;
  }
  
  // ê¸°ë³¸ Web Speech API ì‚¬ìš©
  return <TextToSpeechWeb content={content} />;
}
```

---

## ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€

### Python ì„œë²„ (ë°©ì•ˆ 1)

```bash
pip install edge-tts fastapi uvicorn
```

### Next.js (ë°©ì•ˆ 1)

```bash
# ì¶”ê°€ íŒ¨í‚¤ì§€ ë¶ˆí•„ìš” (ê¸°ë³¸ fetch ì‚¬ìš©)
```

---

## ğŸš€ ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ

### Phase 1: Web Speech API ê°œì„  (ì¦‰ì‹œ ê°€ëŠ¥)

1. âœ… ë” ë‚˜ì€ ë³´ì´ìŠ¤ ì„ íƒ ë¡œì§ ì¶”ê°€
2. âœ… SSML ì§€ì› í™•ì¸ ë° ì ìš©
3. âœ… í˜„ì¬ ê°œì„  ì‚¬í•­ ìœ ì§€ (ë¬¸ì¥ ë‹¨ìœ„ ì½ê¸°, ì¼ì‹œì •ì§€ ë“±)

### Phase 2: edge-TTS ì„œë²„ êµ¬ì¶• (ì„ íƒ ì‚¬í•­)

1. Python ì„œë²„ êµ¬ì¶•
2. Next.js API Route ì¶”ê°€
3. í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™

### Phase 3: ì‚¬ìš©ì ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€

1. ì„¤ì • UIì— TTS ì—”ì§„ ì„ íƒ ì˜µì…˜ ì¶”ê°€
2. ë³´ì´ìŠ¤ ì„ íƒ ì˜µì…˜ ì¶”ê°€
3. ì‚¬ìš©ì ì„¤ì • ì €ì¥

---

## ğŸ’¡ ì°¸ê³  ìë£Œ

- [edge-TTS GitHub](https://github.com/kss2002/edge-TTS)
- [edge-tts ê³µì‹ ë¬¸ì„œ](https://github.com/rany2/edge-tts)
- [Web Speech API ë¬¸ì„œ](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **CORS ì´ìŠˆ**: edge-TTS APIë¥¼ ì§ì ‘ í˜¸ì¶œí•  ê²½ìš° CORS ë¬¸ì œ ë°œìƒ ê°€ëŠ¥
2. **ì„œë²„ ë¦¬ì†ŒìŠ¤**: Python ì„œë²„ë¥¼ êµ¬ì¶•í•  ê²½ìš° ì„œë²„ ë¦¬ì†ŒìŠ¤ ê³ ë ¤ í•„ìš”
3. **ë¹„ìš©**: ë³„ë„ ì„œë²„ ìš´ì˜ ì‹œ ë¹„ìš© ë°œìƒ ê°€ëŠ¥
4. **ë²•ì  ê³ ë ¤**: Microsoft Edge TTS ì‚¬ìš© ì‹œ ë¼ì´ì„¼ìŠ¤ í™•ì¸ í•„ìš”

---

## ğŸ¯ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

**ì¦‰ì‹œ ê°œì„  ê°€ëŠ¥í•œ ì‚¬í•­:**
- âœ… Web Speech APIì˜ ë” ë‚˜ì€ ë³´ì´ìŠ¤ ì„ íƒ
- âœ… í˜„ì¬ êµ¬í˜„ëœ ë¬¸ì¥ ë‹¨ìœ„ ì½ê¸°, ì¼ì‹œì •ì§€ ê¸°ëŠ¥ ìœ ì§€

**ì¥ê¸° ê°œì„  ì‚¬í•­:**
- edge-TTS ì„œë²„ êµ¬ì¶• (ê³ í’ˆì§ˆ ìŒì„±ì´ í•„ìš”í•œ ê²½ìš°)
- ì‚¬ìš©ì ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€

**ê¶Œì¥ ì ‘ê·¼:**
í˜„ì¬ Web Speech API ê°œì„ ì„ ë¨¼ì € ì™„ë£Œí•˜ê³ , í•„ìš”ì‹œ edge-TTS ì„œë²„ë¥¼ ì¶”ê°€í•˜ëŠ” ë‹¨ê³„ì  ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

---

## ğŸ”§ ê·¼ë³¸ì ì¸ ê°œì„  ë°©ì•ˆ (2026ë…„ 1ì›”)

### ë¬¸ì œì  ë¶„ì„

#### 1. ì†ë„ ë¬¸ì œ
- **í˜„ì¬ ìƒí™©**: ê¸°ë³¸ ì†ë„ 2.0ë°°ì†ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë‚˜, 1.0ë°°ì†ì´ë‚˜ 1.5ë°°ì†ìœ¼ë¡œ ë³€ê²½í•˜ë©´ ê¸°ê³„ê°€ ì½ëŠ” ê²ƒì²˜ëŸ¼ ë”±ë”±í•˜ê³  ìì—°ìŠ¤ëŸ½ì§€ ì•ŠìŒ
- **ì›ì¸ ë¶„ì„**:
  - Web Speech APIì˜ `rate` ì†ì„±ì€ ë¸Œë¼ìš°ì €ë§ˆë‹¤ êµ¬í˜„ì´ ë‹¤ë¦„
  - ë‚®ì€ ì†ë„(0.5~1.5)ì—ì„œëŠ” ìŒì„± í•©ì„± ì—”ì§„ì´ ë‹¨ì–´ë¥¼ ëŠì–´ì„œ ì½ê±°ë‚˜ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¦¬ë“¬ ìƒì„±
  - ê¸°ë³¸ ë³´ì´ìŠ¤ì˜ í’ˆì§ˆì´ ë‚®ì„ ê²½ìš° ë”ìš± ë‘ë“œëŸ¬ì§

#### 2. ì†ë„ ë³€ê²½ ì‹œ ìœ„ì¹˜ ë¬¸ì œ
- **í˜„ì¬ ìƒí™©**: ì½ê¸° ë„ì¤‘ ì†ë„ë¥¼ ë³€ê²½í•˜ë©´ ì´ì „ ë¬¸ì¥ìœ¼ë¡œ ëŒì•„ê°€ì„œ ë‹¤ì‹œ ì½ëŠ” ë¬¸ì œ ë°œìƒ
- **ì›ì¸ ë¶„ì„**:
  - í˜„ì¬ ì½”ë“œëŠ” `currentPlayingIndexRef`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ ë‹¨ìœ„ë¡œë§Œ ì¶”ì 
  - ì •í™•í•œ ì¬ìƒ ìœ„ì¹˜(ë¬¸ì¥ ë‚´ ë‹¨ì–´ ìœ„ì¹˜)ë¥¼ ì¶”ì í•˜ì§€ ëª»í•¨
  - ì†ë„ ë³€ê²½ ì‹œ `cancel()` í›„ í˜„ì¬ ë¬¸ì¥ë¶€í„° ë‹¤ì‹œ ì½ê¸° ì‹œì‘

---

### í•´ê²° ë°©ì•ˆ

#### ë°©ì•ˆ 1: ì†ë„ ë²”ìœ„ ì¬ì¡°ì • ë° ê¸°ë³¸ê°’ ë³€ê²½ (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

**ëª©í‘œ**: ê¸°ë³¸ ì†ë„ 1.0ì„ ê¸°ì¤€ìœ¼ë¡œ ëŠë¦¬ê²Œ(0.5~1.0) ë˜ëŠ” ë¹ ë¥´ê²Œ(1.0~3.0) ì„¤ì • ê°€ëŠ¥í•˜ê²Œ í•¨

**êµ¬í˜„ ë°©ë²•**:

1. **ê¸°ë³¸ ì†ë„ ë³€ê²½**: 2.0 â†’ 1.0
2. **ì†ë„ ë²”ìœ„ í™•ì¥**: 0.5 ~ 3.0 (ê¸°ì¡´ 0.5 ~ 2.0)
3. **ë³´ì´ìŠ¤ í’ˆì§ˆ ê°œì„ **: Neural ë³´ì´ìŠ¤ ìš°ì„  ì„ íƒ (ì´ë¯¸ êµ¬í˜„ë¨)
4. **Pitch ì¡°ì ˆ**: ë‚®ì€ ì†ë„ì—ì„œë„ ìì—°ìŠ¤ëŸ¬ìš´ ëŠë‚Œì„ ìœ„í•´ pitchë¥¼ ì•½ê°„ ì¡°ì ˆ

```typescript
// ê¸°ë³¸ ì†ë„ ë³€ê²½
const [speechRate, setSpeechRate] = useState(1.0); // 2.0 â†’ 1.0

// ì†ë„ì— ë”°ë¥¸ pitch ì¡°ì ˆ
const getPitchForRate = (rate: number): number => {
  // ë‚®ì€ ì†ë„(0.5~1.0)ì—ì„œëŠ” pitchë¥¼ ì•½ê°„ ë†’ì—¬ì„œ ë” ìì—°ìŠ¤ëŸ½ê²Œ
  if (rate < 1.0) {
    return 1.1; // ì•½ê°„ ë†’ì€ pitch
  } else if (rate > 2.0) {
    return 0.9; // ë¹ ë¥¸ ì†ë„ì—ì„œëŠ” pitchë¥¼ ë‚®ì¶¤
  }
  return 1.0; // ê¸°ë³¸ê°’
};

// utterance ìƒì„± ì‹œ
utterance.pitch = getPitchForRate(speechRate);
```

**ì¥ì **:
- ì¦‰ì‹œ ì ìš© ê°€ëŠ¥
- ì½”ë“œ ë³€ê²½ ìµœì†Œí™”
- ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì†ë„ ë²”ìœ„ ì œê³µ

**ë‹¨ì **:
- Web Speech APIì˜ í•œê³„ë¡œ ì™„ë²½í•œ í•´ê²°ì€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ

---

#### ë°©ì•ˆ 2: ì •í™•í•œ ì¬ìƒ ìœ„ì¹˜ ì¶”ì  (ê·¼ë³¸ì  í•´ê²°)

**ëª©í‘œ**: ì†ë„ ë³€ê²½ ì‹œ ì •í™•í•œ ìœ„ì¹˜(ë¬¸ì¥ ë‚´ ë‹¨ì–´ ìœ„ì¹˜)ë¶€í„° ì´ì–´ì„œ ì½ê¸°

**êµ¬í˜„ ë°©ë²•**:

1. **`onboundary` ì´ë²¤íŠ¸ í™œìš©**: SpeechSynthesisUtteranceì˜ `onboundary` ì´ë²¤íŠ¸ë¡œ ë‹¨ì–´/ë¬¸ì¥ ê²½ê³„ ì¶”ì 
2. **ì •í™•í•œ ìœ„ì¹˜ ì €ì¥**: í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ë¬¸ì¥ê³¼ ë¬¸ì¥ ë‚´ ë‹¨ì–´ ì¸ë±ìŠ¤ ì €ì¥
3. **ì†ë„ ë³€ê²½ ì‹œ ì •í™•í•œ ìœ„ì¹˜ë¶€í„° ì¬ìƒ**: ì €ì¥ëœ ìœ„ì¹˜ë¶€í„° ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ ì¬ìƒ

```typescript
// ìœ„ì¹˜ ì¶”ì ì„ ìœ„í•œ ref ì¶”ê°€
const currentCharIndexRef = useRef(0); // í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ë¬¸ì ìœ„ì¹˜
const currentWordInSentenceRef = useRef(0); // í˜„ì¬ ë¬¸ì¥ ë‚´ ë‹¨ì–´ ì¸ë±ìŠ¤
const sentenceStartCharIndexRef = useRef(0); // í˜„ì¬ ë¬¸ì¥ì˜ ì‹œì‘ ë¬¸ì ìœ„ì¹˜

// utterance ìƒì„± ì‹œ onboundary ì´ë²¤íŠ¸ ì¶”ê°€
utterance.onboundary = (event: SpeechSynthesisEvent) => {
  if (event.name === 'word') {
    // ë‹¨ì–´ ê²½ê³„ì—ì„œ í˜„ì¬ ìœ„ì¹˜ ì—…ë°ì´íŠ¸
    currentCharIndexRef.current = event.charIndex;
    currentWordInSentenceRef.current = event.charIndex - sentenceStartCharIndexRef.current;
    
    if (process.env.NODE_ENV === 'development') {
      console.log('ë‹¨ì–´ ê²½ê³„:', {
        charIndex: event.charIndex,
        wordIndex: currentWordInSentenceRef.current,
        text: event.utterance.text.substring(0, event.charIndex)
      });
    }
  }
};

// ì†ë„ ë³€ê²½ ì‹œ ì •í™•í•œ ìœ„ì¹˜ë¶€í„° ì¬ìƒ
const handleRateChange = (newRate: number) => {
  if (isPlaying && textPartsRef.current.length > 0) {
    isRateChangingRef.current = true;
    
    // í˜„ì¬ ì¬ìƒ ì¤‘ì¸ utterance ì·¨ì†Œ
    synthRef.current?.cancel();
    
    // í˜„ì¬ ì¬ìƒ ì¤‘ì¸ ë¬¸ì¥ê³¼ ë¬¸ì¥ ë‚´ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°
    const currentSentenceIndex = currentPlayingIndexRef.current;
    const currentSentence = textPartsRef.current[currentSentenceIndex];
    const currentCharIndex = currentCharIndexRef.current;
    
    // í˜„ì¬ ìœ„ì¹˜ë¶€í„° ë¬¸ì¥ ëê¹Œì§€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    const textFromCurrentPosition = currentSentence.substring(currentCharIndex);
    
    // ë‚˜ë¨¸ì§€ ë¬¸ì¥ë“¤ë„ í¬í•¨í•˜ì—¬ ì¬ìƒí•  í…ìŠ¤íŠ¸ ìƒì„±
    const remainingText = [
      textFromCurrentPosition,
      ...textPartsRef.current.slice(currentSentenceIndex + 1)
    ].join(' ');
    
    // ìƒˆë¡œìš´ ì†ë„ë¡œ ì¬ìƒ
    const newUtterance = new SpeechSynthesisUtterance(remainingText);
    newUtterance.rate = newRate;
    newUtterance.pitch = getPitchForRate(newRate);
    
    // ì¬ìƒ ì‹œì‘
    synthRef.current?.speak(newUtterance);
  }
};
```

**ì¥ì **:
- ì •í™•í•œ ìœ„ì¹˜ ì¶”ì  ê°€ëŠ¥
- ì†ë„ ë³€ê²½ ì‹œ ëŠê¹€ ì—†ëŠ” ì¬ìƒ
- ì‚¬ìš©ì ê²½í—˜ í¬ê²Œ ê°œì„ 

**ë‹¨ì **:
- ë¸Œë¼ìš°ì €ë³„ `onboundary` ì´ë²¤íŠ¸ ì§€ì› ì°¨ì´ (Chrome/EdgeëŠ” ì§€ì›, SafariëŠ” ì œí•œì )
- êµ¬í˜„ ë³µì¡ë„ ì¦ê°€

**ë¸Œë¼ìš°ì € í˜¸í™˜ì„±**:
- âœ… Chrome/Edge: ì™„ì „ ì§€ì›
- âš ï¸ Safari: ë¶€ë¶„ ì§€ì› (ë¬¸ì¥ ê²½ê³„ë§Œ)
- âŒ Firefox: ë¯¸ì§€ì›

---

#### ë°©ì•ˆ 3: í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ (ê¶Œì¥)

**ëª©í‘œ**: ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ê³ ë ¤í•œ ìµœì ì˜ í•´ê²°ì±…

**êµ¬í˜„ ë°©ë²•**:

1. **ë¸Œë¼ìš°ì € ê°ì§€**: `onboundary` ì´ë²¤íŠ¸ ì§€ì› ì—¬ë¶€ í™•ì¸
2. **ì§€ì› ë¸Œë¼ìš°ì €**: `onboundary` ì´ë²¤íŠ¸ë¡œ ì •í™•í•œ ìœ„ì¹˜ ì¶”ì 
3. **ë¯¸ì§€ì› ë¸Œë¼ìš°ì €**: í˜„ì¬ ë¬¸ì¥ë¶€í„° ì¬ìƒ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€í•˜ë˜ ê°œì„ )

```typescript
// ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í™•ì¸
const supportsBoundaryEvents = (): boolean => {
  try {
    const utterance = new SpeechSynthesisUtterance('test');
    return 'onboundary' in utterance;
  } catch {
    return false;
  }
};

const isBoundarySupported = useRef(supportsBoundaryEvents());

// ì†ë„ ë³€ê²½ í•¸ë“¤ëŸ¬
const handleRateChange = (newRate: number) => {
  if (isPlaying && textPartsRef.current.length > 0) {
    isRateChangingRef.current = true;
    synthRef.current?.cancel();
    
    if (isBoundarySupported.current) {
      // ì •í™•í•œ ìœ„ì¹˜ ì¶”ì  ë°©ì‹ ì‚¬ìš©
      handleRateChangeWithBoundary(newRate);
    } else {
      // í˜„ì¬ ë¬¸ì¥ë¶€í„° ì¬ìƒ (ê°œì„ ëœ ë°©ì‹)
      handleRateChangeWithoutBoundary(newRate);
    }
  }
};
```

**ì¥ì **:
- ëª¨ë“  ë¸Œë¼ìš°ì €ì—ì„œ ì‘ë™
- ì§€ì› ë¸Œë¼ìš°ì €ì—ì„œëŠ” ìµœì ì˜ ê²½í—˜ ì œê³µ
- ì ì§„ì  ê°œì„  ê°€ëŠ¥

---

### êµ¬í˜„ ìš°ì„ ìˆœìœ„

#### Phase 1: ì¦‰ì‹œ ì ìš© (1ì¼)
1. âœ… ê¸°ë³¸ ì†ë„ 1.0ìœ¼ë¡œ ë³€ê²½
2. âœ… ì†ë„ ë²”ìœ„ 0.5 ~ 3.0ìœ¼ë¡œ í™•ì¥
3. âœ… Pitch ì¡°ì ˆ í•¨ìˆ˜ ì¶”ê°€
4. âœ… ë³´ì´ìŠ¤ ì„ íƒ ë¡œì§ ê°œì„  (ì´ë¯¸ êµ¬í˜„ë¨)

#### Phase 2: ìœ„ì¹˜ ì¶”ì  ê°œì„  (2-3ì¼)
1. âœ… `onboundary` ì´ë²¤íŠ¸ ì§€ì› í™•ì¸
2. âœ… ì •í™•í•œ ìœ„ì¹˜ ì¶”ì  êµ¬í˜„
3. âœ… ì†ë„ ë³€ê²½ ì‹œ ì •í™•í•œ ìœ„ì¹˜ë¶€í„° ì¬ìƒ
4. âœ… ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸

#### Phase 3: ì¶”ê°€ ê°œì„  (ì„ íƒ ì‚¬í•­)
1. ì‚¬ìš©ì ì„¤ì • ì €ì¥ (ë¡œì»¬ ìŠ¤í† ë¦¬ì§€)
2. ì†ë„ í”„ë¦¬ì…‹ ì œê³µ (ëŠë¦¼/ë³´í†µ/ë¹ ë¦„)
3. ìŒì„± í’ˆì§ˆ í–¥ìƒ (edge-TTS ì„œë²„ êµ¬ì¶•)

---

### ì˜ˆìƒ íš¨ê³¼

#### ì†ë„ ë¬¸ì œ í•´ê²°
- âœ… ê¸°ë³¸ ì†ë„ 1.0ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° ì œê³µ
- âœ… 0.5 ~ 3.0 ë²”ìœ„ë¡œ í™•ì¥í•˜ì—¬ ë‹¤ì–‘í•œ ì†ë„ ì„ íƒ ê°€ëŠ¥
- âœ… Pitch ì¡°ì ˆë¡œ ë‚®ì€ ì†ë„ì—ì„œë„ ìì—°ìŠ¤ëŸ¬ìš´ ëŠë‚Œ

#### ìœ„ì¹˜ ë¬¸ì œ í•´ê²°
- âœ… `onboundary` ì´ë²¤íŠ¸ë¡œ ì •í™•í•œ ìœ„ì¹˜ ì¶”ì 
- âœ… ì†ë„ ë³€ê²½ ì‹œ ëŠê¹€ ì—†ëŠ” ì¬ìƒ
- âœ… ì‚¬ìš©ì ê²½í—˜ í¬ê²Œ ê°œì„ 

---

### í…ŒìŠ¤íŠ¸ ê³„íš

1. **ë¸Œë¼ìš°ì €ë³„ í…ŒìŠ¤íŠ¸**:
   - Chrome/Edge: `onboundary` ì´ë²¤íŠ¸ ì •ìƒ ì‘ë™ í™•ì¸
   - Safari: ë¶€ë¶„ ì§€ì› í™•ì¸
   - Firefox: í´ë°± ë°©ì‹ ì‘ë™ í™•ì¸

2. **ì†ë„ í…ŒìŠ¤íŠ¸**:
   - 0.5x ~ 3.0x ë²”ìœ„ì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° í™•ì¸
   - ì†ë„ ë³€ê²½ ì‹œ ëŠê¹€ ì—†ëŠ” ì¬ìƒ í™•ì¸

3. **ì‚¬ìš©ì í…ŒìŠ¤íŠ¸**:
   - ì‹¤ì œ ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
   - ì†ë„ ë° ìœ„ì¹˜ ë¬¸ì œ í•´ê²° ì—¬ë¶€ í™•ì¸

---

### ì°¸ê³  ìë£Œ

- [Web Speech API - SpeechSynthesisUtterance](https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesisUtterance)
- [Web Speech API - SpeechSynthesisEvent](https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesisEvent)
- [onboundary ì´ë²¤íŠ¸ ë¸Œë¼ìš°ì € í˜¸í™˜ì„±](https://caniuse.com/speech-synthesis)

